{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the file (mahabharata)\n",
    "with open('mahabharata.txt', 'r', encoding='utf-8') as f:\n",
    "  text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the BOM character if it exists\n",
    "text = text.replace('\\ufeff', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of characters in dataset: 3641165\n"
     ]
    }
   ],
   "source": [
    "print(\"number of characters in dataset:\", len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE MAHABHARATA\n",
      "\n",
      "ADI PARVA\n",
      "\n",
      "SECTION I\n",
      "\n",
      "Om! Having bowed down to Narayana and Nara, the most exalted male being,\n",
      "and also to the goddess Saraswati, must the word Jaya be uttered.\n",
      "\n",
      "Ugrasrava, the son of Lomaharshana, surnamed Sauti, well-versed in the\n",
      "Puranas, bending with humility, one day approached the great sages of\n",
      "rigid vows, sitting at their ease, who had attended the twelve years’\n",
      "sacrifice of Saunaka, surnamed Kulapati, in the forest of Naimisha. Those\n",
      "ascetics, wishing to hear his wonderful narrations, presently began to\n",
      "address him who had thus arrived at that recluse abode of the inhabitants\n",
      "of the forest of Naimisha. Having been entertained with due respect by\n",
      "those holy men, he saluted those Munis (sages) with joined palms, even\n",
      "all of them, and inquired about the progress of their asceticism. Then\n",
      "all the ascetics being again seated, the son of Lomaharshana humbly\n",
      "occupied the seat that was assigned to him. Seeing that he was\n",
      "comfortably seated, and recovered from fatigue,\n"
     ]
    }
   ],
   "source": [
    "# first 1000 chars\n",
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !&(),-.0123456789:;?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]abcdefghijklmnopqrstuvwxyz‘’“”\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "# unique chars in the text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[72, 57, 50, 69, 1, 58, 68, 1, 70, 65]\n",
      "what is up\n",
      "hi!\n"
     ]
    }
   ],
   "source": [
    "# code to encode and decode vocabulary\n",
    "\n",
    "token_to_int = {token:int for int,token in enumerate(chars)}\n",
    "int_to_token = {int:token for int,token in enumerate(chars)}\n",
    "encode = lambda s: [token_to_int[c] for c in s] # convert string to list of integers\n",
    "decode = lambda l: ''.join([int_to_token[i] for i in l]) # convert list of integers to string\n",
    "\n",
    "print(encode(\"what is up\"))\n",
    "print(decode(encode(\"what is up\")))\n",
    "print(decode([57, 58, 2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3641165]) torch.int64\n",
      "tensor([41, 29, 26,  1, 34, 22, 29, 22, 23, 29, 22, 39, 22, 41, 22,  0,  0, 22,\n",
      "        25, 30,  1, 37, 22, 39, 43, 22,  0,  0, 40, 26, 24, 41, 30, 36, 35,  1,\n",
      "        30,  0,  0, 36, 62,  2,  1, 29, 50, 71, 58, 63, 56,  1, 51, 64, 72, 54,\n",
      "        53,  1, 53, 64, 72, 63,  1, 69, 64,  1, 35, 50, 67, 50, 74, 50, 63, 50,\n",
      "         1, 50, 63, 53,  1, 35, 50, 67, 50,  6,  1, 69, 57, 54,  1, 62, 64, 68,\n",
      "        69,  1, 54, 73, 50, 61, 69, 54, 53,  1])\n"
     ]
    }
   ],
   "source": [
    "# encode the entire text\n",
    "\n",
    "import torch\n",
    "\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and validation split\n",
    "\n",
    "n = int(0.9*len(text))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([41, 29, 26,  1, 34, 22, 29, 22, 23])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([41]) the target is 29\n",
      "when input is tensor([41, 29]) the target is 26\n",
      "when input is tensor([41, 29, 26]) the target is 1\n",
      "when input is tensor([41, 29, 26,  1]) the target is 34\n",
      "when input is tensor([41, 29, 26,  1, 34]) the target is 22\n",
      "when input is tensor([41, 29, 26,  1, 34, 22]) the target is 29\n",
      "when input is tensor([41, 29, 26,  1, 34, 22, 29]) the target is 22\n",
      "when input is tensor([41, 29, 26,  1, 34, 22, 29, 22]) the target is 23\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"when input is {context} the target is {target}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[63, 53,  1, 25, 50, 63, 50, 71],\n",
      "        [54, 68,  6,  1, 68, 50, 58, 53],\n",
      "        [65, 64, 54, 62,  8,  0,  0, 78],\n",
      "        [50, 69,  1, 40, 50, 51, 57, 50]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[53,  1, 25, 50, 63, 50, 71, 50],\n",
      "        [68,  6,  1, 68, 50, 58, 53,  1],\n",
      "        [64, 54, 62,  8,  0,  0, 78, 46],\n",
      "        [69,  1, 40, 50, 51, 57, 50,  8]])\n",
      "----\n",
      "when input is [63] the target is 53\n",
      "when input is [63, 53] the target is 1\n",
      "when input is [63, 53, 1] the target is 25\n",
      "when input is [63, 53, 1, 25] the target is 50\n",
      "when input is [63, 53, 1, 25, 50] the target is 63\n",
      "when input is [63, 53, 1, 25, 50, 63] the target is 50\n",
      "when input is [63, 53, 1, 25, 50, 63, 50] the target is 71\n",
      "when input is [63, 53, 1, 25, 50, 63, 50, 71] the target is 50\n",
      "when input is [54] the target is 68\n",
      "when input is [54, 68] the target is 6\n",
      "when input is [54, 68, 6] the target is 1\n",
      "when input is [54, 68, 6, 1] the target is 68\n",
      "when input is [54, 68, 6, 1, 68] the target is 50\n",
      "when input is [54, 68, 6, 1, 68, 50] the target is 58\n",
      "when input is [54, 68, 6, 1, 68, 50, 58] the target is 53\n",
      "when input is [54, 68, 6, 1, 68, 50, 58, 53] the target is 1\n",
      "when input is [65] the target is 64\n",
      "when input is [65, 64] the target is 54\n",
      "when input is [65, 64, 54] the target is 62\n",
      "when input is [65, 64, 54, 62] the target is 8\n",
      "when input is [65, 64, 54, 62, 8] the target is 0\n",
      "when input is [65, 64, 54, 62, 8, 0] the target is 0\n",
      "when input is [65, 64, 54, 62, 8, 0, 0] the target is 78\n",
      "when input is [65, 64, 54, 62, 8, 0, 0, 78] the target is 46\n",
      "when input is [50] the target is 69\n",
      "when input is [50, 69] the target is 1\n",
      "when input is [50, 69, 1] the target is 40\n",
      "when input is [50, 69, 1, 40] the target is 50\n",
      "when input is [50, 69, 1, 40, 50] the target is 51\n",
      "when input is [50, 69, 1, 40, 50, 51] the target is 57\n",
      "when input is [50, 69, 1, 40, 50, 51, 57] the target is 50\n",
      "when input is [50, 69, 1, 40, 50, 51, 57, 50] the target is 8\n"
     ]
    }
   ],
   "source": [
    "# create batches\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "block_size = 8\n",
    "batch_size = 4 # independent sequences to be processed in parallel\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print('inputs:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets:')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print('----')\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b, t]\n",
    "        print(f\"when input is {context.tolist()} the target is {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[63, 53,  1, 25, 50, 63, 50, 71],\n",
      "        [54, 68,  6,  1, 68, 50, 58, 53],\n",
      "        [65, 64, 54, 62,  8,  0,  0, 78],\n",
      "        [50, 69,  1, 40, 50, 51, 57, 50]])\n"
     ]
    }
   ],
   "source": [
    "print(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 80])\n",
      "tensor(5.0515, grad_fn=<NllLossBackward0>)\n",
      "\n",
      "d(9[!”o[t,w62XYWQe76:62\n",
      "9Xa,BavjX3’Dm\n",
      "”FTDobUDXFRNy\n",
      "X4ec&TDLY4,BzfRQz,W3L:4c\n",
      "7kT1\n",
      "r]\n",
      "JMKF(cS&-SYYguB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(42)\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_emb_table = nn.Embedding(vocab_size,vocab_size)\n",
    "\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        # idx and targets are of size (B, T) (batch, time) (4, 8) in this case\n",
    "        logits = self.token_emb_table(idx) # this will be of size (B, T, C) where C is channels = vocab_size\n",
    "\n",
    "        if targets is None:\n",
    "            loss=None\n",
    "        else:\n",
    "            # cross_entropy expects C as second dim, so we modify the dim of our tensors:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C) # C as the second dim\n",
    "            targets = targets.view(B*T) # make this one dimensional\n",
    "            loss = F.cross_entropy(logits, targets) # should work now\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "\n",
    "    # copied this from karpathy's github (easy code)\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "    \n",
    "\n",
    "    \n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(logits.shape)\n",
    "print(loss)\n",
    "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the Bigram model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an optimizer\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.404163360595703\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "\n",
    "batch_size = 32 # let's up from 4 to 32\n",
    "for steps in range(10000):\n",
    "    xb, yb = get_batch('train') # get a batch of data\n",
    "\n",
    "    # evaluate\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True) # to prevent gradient accumulation\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "t. marathedysther\n",
      "USulive tod ares) Pandr ts tiouind hndsorangthong fitrcrer-borithico iod botharrsa sothe, a oth. ans,\n",
      "he w cof\n",
      "anglin t Ser ran Bhr theg! Aun klo vasondhioAngg Asetu Prives\n",
      "o o thest ld wng btin t whu a we?’\n",
      "atitha wis, f ankem wfr, dinoa, h utithe. ofto fompimee, O o ing, br f aing whravesowh qund acelevey se whe\n",
      "g\n",
      "Visolall, ins\n",
      "Brjonentheshegeeer f An mowhthinfrer hthe was, IO u s Sache Ratha dumy h benl\n",
      "huceinend najowof the thir URauencor aind eraveranthen and thecof O d fo\n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The mathematical trick in self-attention\n",
    "\n",
    "Averaging out the channels of all tokens until the current token. This is kind of a bottleneck but we don't have to worry wbout it right now. Let's implement this on a toy data first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "B, T, C = 4, 8, 2 # batch, time, channel\n",
    "x = torch.randn(B, T, C)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement x[b,t] = mean_{i<=t} x[b, i]\n",
    "xbow = torch.zeros((B, T, C)) # bow = bag of words\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b, :t+1] # (t,C)\n",
    "        xbow[b,t] = torch.mean(xprev, 0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trick: effiency using matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "--\n",
      "b=\n",
      "tensor([[2., 7.],\n",
      "        [6., 4.],\n",
      "        [6., 5.]])\n",
      "--\n",
      "c=\n",
      "tensor([[2.0000, 7.0000],\n",
      "        [4.0000, 5.5000],\n",
      "        [4.6667, 5.3333]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# using lower triangular matrix can help average the values easily as seen in the output\n",
    "a = torch.tril(torch.ones(3, 3))\n",
    "a = a / torch.sum(a, 1, keepdim=True)\n",
    "b = torch.randint(0,10,(3,2)).float()\n",
    "c = a @ b\n",
    "print('a=')\n",
    "print(a)\n",
    "print('--')\n",
    "print('b=')\n",
    "print(b)\n",
    "print('--')\n",
    "print('c=')\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 2: using matrix multiply for a weighted aggregation\n",
    "# same as what we applied above\n",
    "wei = torch.tril(torch.ones(T, T)) # creates a lower triangular matrix\n",
    "wei = wei / wei.sum(1, keepdim=True) # this makes the averaging happen\n",
    "xbow2 = wei @ x # wei is originally (T,T) but will broadcast as (B,T,T). (B, T, T) @ (B, T, C) ----> (B, T, C)\n",
    "torch.allclose(xbow, xbow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3rd way: using softmax\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril==0, float('-inf')) # wherever tril=0, replace by -inf\n",
    "wei = F.softmax(wei, dim=1) # softmax will do the same matrix\n",
    "xbow3 = wei @ x\n",
    "\n",
    "torch.allclose(xbow, xbow3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# v4: self-attention\n",
    "\n",
    "torch.manual_seed(69)\n",
    "B,T,C = 4,8,32\n",
    "x = torch.randn(B,T,C)\n",
    "\n",
    "# single attention head\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "\n",
    "k = key(x) # B x T x 16\n",
    "q = query(x) # B x T x 16\n",
    "wei = q @ k.transpose(-2, -1)   # transpose along the last 2 dimensions\n",
    "                                 # BxTx16 @ Bx16xT --> BxTxT\n",
    "\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "#wei = torch.zeros((T,T))\n",
    "wei = wei.masked_fill(tril==0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "\n",
    "v = value(x)\n",
    "out = wei @ v\n",
    "\n",
    "#out = wei@x\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3989, 0.6011, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2886, 0.1684, 0.5431, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5726, 0.2702, 0.0419, 0.1153, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2158, 0.3648, 0.1488, 0.0369, 0.2337, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1819, 0.0757, 0.3826, 0.1124, 0.0363, 0.2110, 0.0000, 0.0000],\n",
       "        [0.1323, 0.1567, 0.0327, 0.2290, 0.2709, 0.0831, 0.0953, 0.0000],\n",
       "        [0.2437, 0.0516, 0.1671, 0.0837, 0.0228, 0.3515, 0.0353, 0.0443]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
